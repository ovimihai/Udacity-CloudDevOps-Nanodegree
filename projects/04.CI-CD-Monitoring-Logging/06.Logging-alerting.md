# Section 4

## Surface Critical Server Errors for Diagnosis Using Centralized Logging

Errors and unhealthy states are important to know about, wouldn't you say? But, too often, server errors are silenced by hasty reboots or simply never having an outlet in the first place. If a server has an error in a forest, but no one is there to hear it, did it actually happen? Why is the server in the forest in the first place?

UdaPeople chose Prometheus as a monitoring solution since it is open-source and versatile. Once configured properly, Prometheus will turn our server's errors into sirens that no one can ignore.

### Setup - Prometheus Server in AWS EC2

https://youtu.be/PSXrbE54FqQ

* Manually create an EC2 instance and SSH into it.

* Set up Prometheus Server on EC2 following [these instructions](https://codewizardly.com/prometheus-on-aws-ec2-part1/).

* Configure Prometheus for AWS Service Discovery following [these instructions](https://codewizardly.com/prometheus-on-aws-ec2-part3/).
> 
> **Tip**: After makinig edits to the _prometheus.yml_ file in the Prometheus EC2 instance, you can consider restarting the EC2 instance. Consequently, SSH log into the EC2 instance again, and start the Prometheus server.

# To Do

## 1\. Setup Back-End Monitoring

In order for EC2 server instances to speak to Prometheus, we need to install an "exporter" in each one. Create a job that uses Ansible to go into the EC2 instance and install the exporter.

* Add a section to your back-end configuration job to install the `node_exporter` for Prometheus monitoring. This should be done using Ansible. Your playbook can simulate the steps in [this tutorial](https://codewizardly.com/prometheus-on-aws-ec2-part2/).

* After deploy, ensure your backend is being discovered by the Prometheus Server.
> 
> **Tip**: When you see error like: _err="opening storage failed: lock DB directory: resource temporarily unavailable"_, you can consider restarting the Prometheus server.

> **Tip**: For your Backend EC2 instance, ensure that the port 9100 is open for inbound connections.

* Provide a screenshot of a graph of your EC2 instance including available memory, available disk space, and CPU usage. **\[SCREENSHOT11\]**

![Graphs of CPU, Disk and Memory utilization on systems being monitored.](https://video.udacity-data.com/topher/2021/October/616e5e51_screenshot11-a/screenshot11-a.png)

**SCREENSHOT11** Example - Free memory  
Note that 3 screenshots are required i.e. node free memory, node CPU usage, and node disk usage.

* Provide a screenshot of your Prometheus Server. **\[URL05\_SCREENSHOT\]**

It should look like this:

![**[URL05_SCREENSHOT>** Screenshot of Running Prometheus server and Udapeople server (showing State UP)](https://video.udacity-data.com/topher/2021/October/616e5f1a_url05-screenshot/url05-screenshot.png)

**\[URL05\_SCREENSHOT\]** Example - Screenshot of Running Prometheus server and Udapeople server (showing State UP)

## 2\. Setup Alerts

Now that Prometheus and our EC2 instance have an open line of communication, we need to set up some alerts. The UdaPeople dev team loves their chat tool and wants to receive an alert in chat when the server starts running out of memory or disk space. Set up a job to make that dream a reality.

* SSH into your Prometheus Server.

* Install and configure AlertManager by following [these instructions](https://codewizardly.com/prometheus-on-aws-ec2-part4/). To summarize, the steps would be similar to:
    
```
mkdir alertmanager
cd alertmanager
wget https://github.com/prometheus/alertmanager/releases/download/v0.23.0/alertmanager-0.23.0.linux-amd64.tar.gz
tar xvzf alertmanager-0.23.0.linux-amd64.tar.gz
cd alertmanager-0.23.0.linux-amd64/
# Edit the alertmanager.yml file
./alertmanager --config.file=./alertmanager.yml
```

* You can decide if you will use Slack, email, or another messaging service. Our examples are using Slack, but you should feel free to use the messaging service to which you are most accustomed.
> 
> **Tip**: If you choose Gmail notification, you will have to integrate Google account using the [Google's App password](https://codewizardly.com/prometheus-on-aws-ec2-part4/#generate-an-app-password) rather than your own account password.

* Set up an alert for low memory, or instance down, or any other condition you can control to intentionally cause an alert.

* Provide a screenshot of an alert that was sent by Prometheus. **\[SCREENSHOT12\]**

![Alerts from a failing system that is being monitored.](https://video.udacity-data.com/topher/2020/July/5f20da5d_screenshot12/screenshot12.png)

**SCREENSHOT12** Example