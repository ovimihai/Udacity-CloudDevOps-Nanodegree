## Autoscaling with CPU or Memory

If you did the [Scaling Demo](https://kubernetes.io/docs/tutorials/kubernetes-basics/scale/scale-intro/) earlier, you already saw one way to scale your apps:

`kubectl scale {deployment name} --replicas={desired number of replicas}`

The Horizontal Pod Autoscaler does this work for you.

One of the "killer" features of Kubernetes is the ability to set up auto-scaling via the [Horizontal Pod Autoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/). How does this work? The Kubernetes HPA (Horizontal Pod Autoscaler) will automatically scale the number of pods (_remember they can contain multiple containers_) in a replication controller, deployment or replica set. The scaling is based on CPU utilization, memory or custom metrics defined in the Kubernetes Metrics Server.

![Kubernetes HPA (Horizontal Pod Autoscaler)](https://video.udacity-data.com/topher/2020/February/5e56bc69_kubernetes-hpa/kubernetes-hpa.png)

**Kubernetes HPA (Horizontal Pod Autoscaler)**

There is a Docker article [Kubernetes autoscaling in UCP](https://success.docker.com/article/kubernetes-autoscaling-in-ucp) that is a good guide to go deeper on this topic and experiment with it yourself.

https://youtu.be/MFQ9lOUIit0

The Horizontal Pod Autoscaler built into Kubernetes is incredibly useful for expanding the number of Pods available based on processing or memory needs. The underlying algorithm itself, somewhat simplified, is as follows:

`newNumPods = ceil(currentNumPods * (currentMetric / desiredMetric))`

This means, if by some metric, we are currently at 2.5X our desired metric level, we will scale up our number of pods by 2.5X, rounded up to the nearest one pod.